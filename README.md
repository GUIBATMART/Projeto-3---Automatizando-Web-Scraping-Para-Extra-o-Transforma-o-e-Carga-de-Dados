# ğŸš€ Projeto 3 â€” Automatizando Web Scraping para ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga de Dados (ETL)

## ğŸ“Œ Sobre o Projeto

Este projeto implementa um pipeline completo de **ETL (Extract, Transform, Load)** utilizando Python.

O sistema realiza:

- ğŸ” ExtraÃ§Ã£o automatizada de dados a partir de uma pÃ¡gina HTML
- ğŸ”„ TransformaÃ§Ã£o e tratamento das informaÃ§Ãµes
- ğŸ“Š GeraÃ§Ã£o automÃ¡tica de planilha Excel
- ğŸ—„ï¸ PersistÃªncia dos dados em banco SQLite

O fluxo Ã© executado de forma automatizada, demonstrando na prÃ¡tica conceitos de **Web Scraping, manipulaÃ§Ã£o de dados e engenharia de dados bÃ¡sica**.

---

## ğŸ—ï¸ Arquitetura do Processo

O pipeline segue as seguintes etapas:

### 1ï¸âƒ£ Extract
- ConexÃ£o com pÃ¡gina HTML
- Captura estruturada dos dados via BeautifulSoup

### 2ï¸âƒ£ Transform
- Limpeza de dados
- ConversÃ£o de unidades
- PadronizaÃ§Ã£o de valores

### 3ï¸âƒ£ Load
- ExportaÃ§Ã£o para planilha Excel
- InserÃ§Ã£o dos dados em banco SQLite

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python
- Requests
- BeautifulSoup
- OpenPyXL
- SQLite
- Pandas (se aplicÃ¡vel)

---

## ğŸ“‚ Estrutura do Projeto

```
Projeto-3/
â”‚
â”œâ”€â”€ dados/
â”œâ”€â”€ banco/
â”œâ”€â”€ output.xlsx
â”œâ”€â”€ script.py
â””â”€â”€ README.md
```

---

## â–¶ï¸ Como Executar o Projeto

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone https://github.com/GUIBATMART/Projeto-3---Automatizando-Web-Scraping-Para-Extra-o-Transforma-o-e-Carga-de-Dados.git
```

### 2ï¸âƒ£ Acesse a pasta do projeto

```bash
cd Projeto-3---Automatizando-Web-Scraping-Para-Extra-o-Transforma-o-e-Carga-de-Dados
```

### 3ï¸âƒ£ Instale as dependÃªncias

```bash
pip install requests beautifulsoup4 openpyxl pandas
```

### 4ï¸âƒ£ Execute o script

```bash
python script.py
```

---

## ğŸ“Š Resultados Gerados

Ao executar o projeto, serÃ£o gerados:

- âœ… Arquivo Excel com os dados tratados
- âœ… Banco de dados SQLite populado
- âœ… Processo automatizado de ponta a ponta

---

## ğŸ¯ Objetivo do Projeto

Este projeto foi desenvolvido com foco em:

- Praticar construÃ§Ã£o de pipelines ETL
- Aplicar Web Scraping de forma estruturada
- Consolidar conhecimentos em manipulaÃ§Ã£o de dados
- Simular cenÃ¡rios reais de Engenharia de Dados

---

## ğŸ“ˆ PossÃ­veis Melhorias Futuras

- ImplementaÃ§Ã£o de logs estruturados
- Tratamento avanÃ§ado de exceÃ§Ãµes
- ContainerizaÃ§Ã£o com Docker
- Agendamento automÃ¡tico (cron / task scheduler)
- IntegraÃ§Ã£o com PostgreSQL

---

## ğŸ‘¨â€ğŸ’» Autor

**Guilherme Batista**  
Analista de Sistemas | AutomaÃ§Ã£o de Processos | Engenharia de Dados em evoluÃ§Ã£o  

ğŸ”— GitHub: https://github.com/GUIBATMART  
ğŸ”— LinkedIn: www.linkedin.com/in/guilherme-batista-175b31223
